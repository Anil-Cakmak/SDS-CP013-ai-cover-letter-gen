{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Display instructions to the user\n",
    "st.title(\"AI-Powered Cover Letter Generator\")\n",
    "st.write(\"Fill in the details below to generate a customized, professional cover letter.\")\n",
    "\n",
    "# Create input fields\n",
    "textbox_company = st.text_input(\"Enter Company Name:\")\n",
    "textbox_job = st.text_input(\"Enter Job Title:\")\n",
    "textbox_resume = st.text_area(\"Enter Your Resume Summary:\")\n",
    "\n",
    "# Hugging Face authentication\n",
    "HUGGING_FACE_TOKEN = \"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\"  # Replace with your actual Hugging Face token\n",
    "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HUGGING_FACE_TOKEN\n",
    "\n",
    "# Load the summarization and text generation models\n",
    "try:\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "except Exception as e:\n",
    "    st.error(f\"Error loading models: {e}\")\n",
    "\n",
    "# Helper function for chunking\n",
    "def chunk_text(text, max_tokens, tokenizer):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "    return [tokens[i: i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n",
    "\n",
    "# Generate cover letter\n",
    "if st.button(\"Generate Cover Letter\"):\n",
    "    if not textbox_company or not textbox_job or not textbox_resume:\n",
    "        st.warning(\"Please fill in all fields before generating a cover letter.\")\n",
    "    else:\n",
    "        with st.spinner(\"Generating your cover letter...\"):\n",
    "            try:\n",
    "                # Tokenizer for splitting into manageable chunks\n",
    "                tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "                # Input preparation\n",
    "                ARTICLE = f\"I am applying for the position of {textbox_job} at {textbox_company}. {textbox_resume}\"\n",
    "\n",
    "                # Chunk input text if it's too long\n",
    "                max_input_tokens = 1024  # BART's token limit for input and output\n",
    "                chunks = chunk_text(ARTICLE, max_input_tokens - 200, tokenizer)\n",
    "\n",
    "                # Summarize each chunk and combine\n",
    "                summarized_resume = \"\"\n",
    "                for chunk in chunks:\n",
    "                    chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "                    summarized = summarizer(chunk_text, max_length=200, min_length=50, do_sample=False)\n",
    "                    summarized_resume += summarized[0][\"summary_text\"] + \" \"\n",
    "\n",
    "\n",
    "                # Display the result\n",
    "                st.subheader(\"Generated Cover Letter\")\n",
    "                st.write(summarized_resume.strip())\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error generating cover letter: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
